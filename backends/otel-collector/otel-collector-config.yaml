receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

processors:
  batch:
    timeout: 1s
    send_batch_size: 1024

  resource:
    attributes:
      - key: service.name
        action: upsert
        from_attribute: service.name

exporters:
  # Export to Grafana LGTM stack via OTLP
  otlp/grafana:
    endpoint: http://lgtm:4317
    tls:
      insecure: true

  # Prometheus exporter for metrics - configuration corrig√©e
  prometheus:
    endpoint: "0.0.0.0:8889"
    namespace: "fastapi"
    const_labels:
      service: "fastapi-openai-rag"
    send_timestamps: true
    metric_expiration: 180m
    enable_open_metrics: true

  # Debug exporter (console output)
  debug:
    verbosity: detailed
    sampling_initial: 5
    sampling_thereafter: 200

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch, resource]
      exporters: [otlp/grafana, debug]

    metrics:
      receivers: [otlp]
      processors: [batch, resource]
      exporters: [prometheus, debug]

    logs:
      receivers: [otlp]
      processors: [batch, resource]
      exporters: [debug]
